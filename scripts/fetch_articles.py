import os, json, openai
from datetime import datetime
from Bio import Entrez
from pathlib import Path

# ===== é…ç½® =====
Entrez.email = "your_email@example.com"  # âš ï¸ è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„é‚®ç®±
openai.api_key = os.getenv("OPENAI_API_KEY")  # ç¡®ä¿ GitHub Secrets å·²è®¾ç½®

KEYWORD = "exosome"
MAX_RESULTS = 5
OUT = Path("public/articles")

# ===== è·å– PubMed ID =====
def fetch_ids():
    try:
        h = Entrez.esearch(db="pubmed", term=KEYWORD, retmax=MAX_RESULTS, sort="pub+date")
        return Entrez.read(h).get("IdList", [])
    except Exception as e:
        print("æŠ“å– PubMed ID å¤±è´¥:", e)
        return []

# ===== è·å–æ–‡ç« è¯¦æƒ… =====
def fetch_details(pmid):
    try:
        with Entrez.efetch(db="pubmed", id=pmid, retmode="xml") as h:
            rec = Entrez.read(h)
        arts = rec.get("PubmedArticle", [])
        if not arts:
            print(f"æœªæ‰¾åˆ°æ–‡ç« ï¼š{pmid}")
            return {}
        art = arts[0]
        cite = art.get("MedlineCitation", {})
        artinfo = cite.get("Article", {})
        title_en = artinfo.get("ArticleTitle", "")
        abst = artinfo.get("Abstract", {}).get("AbstractText", [""])
        abstract_en = " ".join(abst) if isinstance(abst, list) else abst
        src = cite.get("MedlineJournalInfo", {}).get("MedlineTA", "")
        pub = artinfo.get("Journal", {}).get("JournalIssue", {}).get("PubDate", {})
        year = pub.get("Year", "")
        month = pub.get("Month", "01")
        return {
            "pmid": pmid,
            "title_en": title_en,
            "abstract_en": abstract_en,
            "source": src,
            "pubyear": year,
            "pubmonth": month,
        }
    except Exception as e:
        print(f"è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥ï¼ˆPMID:{pmid}ï¼‰:", e)
        return {}

# ===== ChatGPT ç¿»è¯‘å‡½æ•° =====
def translate(text, prompt):
    if not openai.api_key:
        print("âŒ OPENAI_API_KEY æœªè®¾ç½®")
        return "[æœªè®¾ç½® API KEY]"
    try:
        print(f"ğŸš€ è°ƒç”¨ GPT ç¿»è¯‘ï¼ˆæç¤ºï¼š{prompt[:10]}...ï¼‰")
        r = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt + "\n\n" + text}],
            temperature=0.3,
            max_tokens=500
        )
        return r.choices[0].message.content.strip()
    except Exception as e:
        print("ç¿»è¯‘å¤±è´¥:", e)
        with open("translate_error.log", "a", encoding="utf-8") as f:
            f.write(f"ç¿»è¯‘å¤±è´¥: {e}\n")
        return "[ç¿»è¯‘å¤±è´¥]"

# ===== ä¸»ç¨‹åºå…¥å£ =====
def main():
    OUT.mkdir(parents=True, exist_ok=True)
    data_list = []

    pmids = fetch_ids()
    print(f"æŠ“å–åˆ°çš„ PubMed IDï¼š{pmids}")

    for pmid in pmids:
        d = fetch_details(pmid)
        if not d or not d.get("abstract_en"):
            continue

        # ç¿»è¯‘å’Œæ ‡é¢˜ç”Ÿæˆ
        zh = translate(d["abstract_en"], "ç¿»è¯‘ä¸ºä¸­æ–‡ï¼š")
        title = translate(d["abstract_en"], "ç”Ÿæˆä¸è¶…è¿‡15å­—çš„ä¸­æ–‡æ ‡é¢˜ï¼š")

        dt = datetime.utcnow()
        rec = {
            "id": pmid,
            "title": title[:15] if title else "[æ— æ ‡é¢˜]",
            "full_title": d["title_en"],
            "abstract_en": d["abstract_en"],
            "abstract_zh": zh,
            "source": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
            "date": f"{d['pubyear']}-{d.get('pubmonth', '01')}",
            "time": dt.strftime("%Y-%m-%d %H:%M UTC")
        }

        # å†™å…¥å•ç¯‡ JSON
        with open(OUT / f"{pmid}.json", "w", encoding="utf-8") as f:
            json.dump(rec, f, ensure_ascii=False, indent=2)

        data_list.append(rec)

    # å†™å…¥ç´¢å¼•é¡µ
    with open(OUT / "index.json", "w", encoding="utf-8") as f:
        json.dump(data_list, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main()
